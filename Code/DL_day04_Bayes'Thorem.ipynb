{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 베이즈 정리\n",
    "* 미래의 일어날 사건을 예측하는 것\n",
    "* 과거의 데이터를 사용한다\n",
    "* 우도(likehood)표를 사용하여 통계를 정리한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P(A): 사건 A가 일어날 확률\n",
    "P(B): 사건 B가 일어날 확률\n",
    "P(A|B): 사건 B가 발생되었을 때, 사건A가 일어날 확률\n",
    "P(B|A)\n",
    "P(A|B)=P(B|A)*P(A)/P(B) : 베이즈 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "예를 들어,\n",
    "스팸필터가 있다고하자.\n",
    "\n",
    "홍길동씨가 받은 메일의 80%가 스팸메일이다.\n",
    "스펨메일의 95%에서 '대출'이라는 단어가 발견되었다.\n",
    "정상메일의 2%에서 '대출'이라는 단어가 발견되었다.\n",
    "---------------------------------------------------------\n",
    "이때, '대출'이라는 단어가 제목에서 발견되었는데\n",
    "스팸일 확률은?\n",
    "---------------------------------------------------------\n",
    "P(스팸|대출)=P(대출|스팸)*P(스팸)/P(대출)\n",
    "            =0.95*0.8/P(대출)\n",
    "    \n",
    "P(대출)=P(대출|스팸)*P(스팸)+P(대출|정상)*P(정상)\n",
    "       =0.95*0.8+0.02*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words(BOW)\n",
    "* 단어들의 등장 횟수로 표현(단어가방)\n",
    "1) 주어진 단어에 대해 고유의 인덱스 부여\n",
    "2) 단어의 등장 횟수 벡터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt=Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "token=\"오늘은 금요일입니다. 내일은 토요일입니다.다음주 화요일에는 특강이 있습니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tok=Tokenizer()\n",
    "tok.fit_on_texts(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규식을 사용하여 문자열에서 '.'을 제거하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오늘은 금요일입니다 내일은 토요일입니다다음주 화요일에는 특강이 있습니다'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token=re.sub(\"\\.\",\" \",token)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "token=okt.morphs(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import *\n",
    "from nltk.tag import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'오늘': 0, '은': 1, '금요일': 2, '입니다': 3, '내일': 4, '토요일': 5, '다음주': 6, '화요일': 7, '에는': 8, '특강': 9, '이': 10, '있습니다': 11}\n"
     ]
    }
   ],
   "source": [
    "word2Idx={}\n",
    "bow=[]\n",
    "for voc in token:\n",
    "    if voc not in word2Idx.keys(): # 워드투인덱스 키에 없다면 (중복된 단어는 두번 저장되지 않는다)\n",
    "        word2Idx[voc]=len(word2Idx) # 딕셔너리의 len()은 저장된 요소의 개수\n",
    "        bow.insert(len(word2Idx)-1,1)\n",
    "    else:\n",
    "        index=word2Idx.get(voc)\n",
    "        bow[index]=bow[index+1]\n",
    "print(word2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 2 1 2 1]]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text=['you know i want your love. because i love you']\n",
    "vec=CountVectorizer() #BOW 생성 클라스\n",
    "vec=CountVectorizer(stop_words=['I']) # 불용어 사용\n",
    "vec=CountVectorizer(stop_words='english') #불용어 사용 \n",
    "vec.fit_transform(text)\n",
    "vec.vocabulary\n",
    "print(vec.fit_transform(text).toarray())\n",
    "print(vec.vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram (문장간 유사도 조사)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1) 오늘 역삼에서 맛있는 돈가스를 먹었다.\n",
    "2) 역삼에서 먹었던 오늘의 돈가스는 맛있었다.\n",
    "\n",
    "-2번 문장에 대해 1번 문장이 얼마나 유사한지 출력\n",
    "\n",
    "-1번 문장에대해 n=2로 하여 문장을 분리하면,\n",
    " 오늘 늘 역 역삼 ...다.\n",
    " 만약 길이가 20이라 가정하고, 2번문장에 대해서도 n=2로 하여 문장을 분리했을 때,\n",
    " 공통으로 존재하는 단어가 5개라면,\n",
    " 5/20=25%의 유사도를 가진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
