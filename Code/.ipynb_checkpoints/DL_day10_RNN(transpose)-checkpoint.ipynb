{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# < Machine Learning project >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 문제 정의 \n",
    " - 회원증가, 카드 매출 증대, 불량 원인 찾기, 생산 비용 절감(최근, 최적 전력 소비량 예측 issue)\n",
    "\n",
    "2. 머신 러닝을 사용하지 않는 방법\n",
    " - 자동 테스트가 어렵다. 데이터의 의존관계 복잡\n",
    " - 처리 파이프라인 구조 복잡 (작업 단위를 모듈화)\n",
    "\n",
    "3. 시스템 설치\n",
    "- '예측 결과를 어떻게 사용할 것인가'에 대한 정의 필요\n",
    "- 예측 오류의 영향 고려\n",
    "- 목표 성능 정의, 포기 지점 설정\n",
    "\n",
    "4. 알고리즘 선택\n",
    "- 이전의 프로젝트 경험이 없는 경우, 도메인 날리지가 없는 경우,\n",
    " --> 군집화를 통해 시각화하여 데이터 분석 후, 알고리즘 선택할 수 있다\n",
    "    \n",
    "5. 특징, 로그(기록), 설계\n",
    "- 수치벡터(더미 변수)로 변환하는 작업 필요\n",
    "  ex) 라벨 인코더, 원핫 인코더\n",
    "    \n",
    "6. 데이터 전처리\n",
    "- 주어진 문제에 따라 이상치 처리, 정규화, 단어 제거, 더미 변수화, 잡음 제거\n",
    "\n",
    "7. 학습 및 파라미터 튜닝\n",
    "- 과적합 방지(교차 검증) \n",
    "- 규제화\n",
    "- 학습 곡선\n",
    "\n",
    "8. 시스템 통합\n",
    "- 모니터링 (비즈니스 성과) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <머신러닝 시스템에서 문제 해결>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- 확률 -> 자동 테스트가 어렵다\n",
    "  예측 성능 올리기 -> 시스템 복잡 -> 유지 보수 필요\n",
    "  * 시스템 변화에 잘 대응하는 ML 시스템을 구축해야 한다\n",
    "  --> 예측 모델(여러 알고리즘) 모듈화, A/B 테스트 수행 \n",
    "  --> 병렬 테스트 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <머신러닝 알고리즘 선택 방법>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- 분류:클래스\n",
    "- 회귀:수치\n",
    "- 군집화:\n",
    "- 차원 축소:연산량 줄임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "그레디언트 디센트(초기 w값을 랜덤으로 주어 기울기가 최저점인 곳을 local에서 찾음)\n",
    "-> rmsprop(속도를 고려하여 보강한 알고리즘)  \n",
    "-> 아담"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k-means\n",
    "k값에 따라 편차가 크긴하지만 성능이 괜찮다\n",
    "(k값을 구하는 방법으로는 엘보 그래프를 통해 적정한 k값 구할 수 있다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <분류 결과 평가 방법>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- 정밀도, 재현율, f 측정값, 정확도\n",
    "- 정밀도와 재현율 가장 의미 있다.\n",
    "1.\n",
    "accuracy(정확도)=정답 일치 data/전체 data\n",
    "precision(정밀도)=실제 스팸메일/분류기가 스팸으로 분류한 메일\n",
    "recall(재현율)=분류기가 분류한 스팸메일/실제 스팸메일\n",
    "\n",
    "** 프로젝트 구현시, f-점수를 비교하는게 제일 좋다.\n",
    "f-점수는 :정밀도와 재현율의 조화평균(--> 둘다 높아야 한다)\n",
    "    =2/ (1/정밀도)+(1/재현율) (--> 수치 1에 가까울 수록 정밀도와 재현율 둘다 높다)\n",
    "\n",
    "    \n",
    "2.    \n",
    "결정 계수(R제곱)    \n",
    ": 항상 평균을 출력하는 예측모델보다 성능이 더 좋은가?\n",
    "    --> 1에 가까울수록 성능이 좋고, 0에 가까울수록 성능이 안좋다.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN에서 \n",
    "전체 오차에 대한 미분/가중치에 대한 미분 = (각 오차의 미분/가중치에 대한 미분) 의 총합\n",
    "\n",
    "RNN은 depth(3이하)가 낮은 신경망에 대해서는 적용가능하다.\n",
    "but, 깊이가 깊어질 경우 vanishing gradient 현상이 나타난다. \n",
    "\n",
    "LSTM \n",
    ": shared weight system에서 깊은 신경망 사용시, vanishing gradient 현상을 방지하기 위해\n",
    "    weight 전달시 중간에서 w값을 조절하는 알고리즘\n",
    "    \n",
    "--> w값 전달하는 신경망과 더불어 메모리 cell(정보를 얼마나 전달할 지 조절) 신경망이 추가적으로 붙는 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr=np.arange(0, 4*2*4)\n",
    "len(arr)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7]],\n",
       "\n",
       "       [[ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]],\n",
       "\n",
       "       [[16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]],\n",
       "\n",
       "       [[24, 25, 26, 27],\n",
       "        [28, 29, 30, 31]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=arr.reshape([4,2,4])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "<built-in method sum of numpy.ndarray object at 0x000001FC7F96FDF0>\n"
     ]
    }
   ],
   "source": [
    "print(v.ndim)\n",
    "print(v.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "v.sum(axis=0) #행단위\n",
    "print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  6,  8, 10],\n",
       "       [20, 22, 24, 26],\n",
       "       [36, 38, 40, 42],\n",
       "       [52, 54, 56, 58]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.sum(axis=1) #열단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6,  22],\n",
       "       [ 38,  54],\n",
       "       [ 70,  86],\n",
       "       [102, 118]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.sum(axis=2) #depth단위"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transpose를 통해 축 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.dynamic_rnn   tf.transpose(대상,[0,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTensor=np.arange(2*3*4).reshape(2,3,4)  \n",
    "myTensor # --> 2,3,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0, 12],\n",
       "        [ 4, 16],\n",
       "        [ 8, 20]],\n",
       "\n",
       "       [[ 1, 13],\n",
       "        [ 5, 17],\n",
       "        [ 9, 21]],\n",
       "\n",
       "       [[ 2, 14],\n",
       "        [ 6, 18],\n",
       "        [10, 22]],\n",
       "\n",
       "       [[ 3, 15],\n",
       "        [ 7, 19],\n",
       "        [11, 23]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(myTensor) # --> 4,3,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(myTensor,[1,2,0]).shape # --> 3,4,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/user/Downloads/mnist2/data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/user/Downloads/mnist2/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/user/Downloads/mnist2/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/user/Downloads/mnist2/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets(\"/Users/user/Downloads/mnist2/data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "total_epoch=30\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input=28 #가로픽셀수\n",
    "n_step=28 # 세로픽셀수(입력단계, step)\n",
    "n_hidden=128 \n",
    "n_class=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x=tf.placeholder(tf.float32, [None, n_step, n_input])\n",
    "y=tf.placeholder(tf.float32, [None,n_class])\n",
    "w=tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "b=tf.Variable(tf.random_normal([n_class]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 학습에 쓰여질 CELL 정의\n",
    "종류 : BasicRNNCell/BasicLSTMCell/BasicGRUCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에폭:    1 avg cost= 0.554\n",
      "에폭:    2 avg cost= 0.247\n",
      "에폭:    3 avg cost= 0.197\n",
      "에폭:    4 avg cost= 0.160\n",
      "에폭:    5 avg cost= 0.137\n",
      "에폭:    6 avg cost= 0.128\n",
      "에폭:    7 avg cost= 0.114\n",
      "에폭:    8 avg cost= 0.108\n",
      "에폭:    9 avg cost= 0.104\n",
      "에폭:   10 avg cost= 0.104\n",
      "에폭:   11 avg cost= 0.096\n",
      "에폭:   12 avg cost= 0.093\n",
      "에폭:   13 avg cost= 0.086\n",
      "에폭:   14 avg cost= 0.090\n",
      "에폭:   15 avg cost= 0.082\n",
      "에폭:   16 avg cost= 0.080\n",
      "에폭:   17 avg cost= 0.083\n",
      "에폭:   18 avg cost= 0.074\n",
      "에폭:   19 avg cost= 0.076\n",
      "에폭:   20 avg cost= 0.069\n",
      "에폭:   21 avg cost= 0.073\n",
      "에폭:   22 avg cost= 0.065\n",
      "에폭:   23 avg cost= 0.075\n",
      "에폭:   24 avg cost= 0.072\n",
      "에폭:   25 avg cost= 0.065\n",
      "에폭:   26 avg cost= 0.069\n",
      "에폭:   27 avg cost= 0.062\n",
      "에폭:   28 avg cost= 0.061\n",
      "에폭:   29 avg cost= 0.069\n",
      "에폭:   30 avg cost= 0.059\n"
     ]
    }
   ],
   "source": [
    "# Cell 정의 후, dynamic_rnn 을 구성하는 것으로 신경망 구성이 끝난다.\n",
    "# dynamic_rnn에서는 (cell이름, inputdata, inputdata type)\n",
    "cell=tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "outputs, states=tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)\n",
    "# 첫번째 인자로 \n",
    "\n",
    "# Y:[batch_size,nclass]형태로 출력된다\n",
    "# outputs:[batch_size,n_step,n_hidden]형태로 출력된다\n",
    "# 따라서, [n_step,batch_size,n_hidden]으로 transpose해주고,\n",
    "#        [batch_size,n_hidden]만 사용하면 된다. --> w와 곱하여 n_class만 반환하기 위해서\n",
    "\n",
    "outputs=tf.transpose(outputs,[1,0,2]) #[n_step,batch_size,n_hidden]\n",
    "outputs=outputs[-1] # nstep을 빼준다. 그리고 w와 matmul하고 b를 더하면 Y값!!\n",
    "model=tf.matmul(outputs,w)+b\n",
    "    \n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    logits=model, labels=y))\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch=int(mnist.train.num_examples/batch_size)\n",
    "for epoch in range(total_epoch):\n",
    "    total_cost=0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys=mnist.train.next_batch(batch_size)\n",
    "        batch_xs=batch_xs.reshape((batch_size, n_step, n_input))\n",
    "        # [batch_size, nstep, ninput]        \n",
    "        _, cv=sess.run([optimizer, cost], feed_dict={x:batch_xs, y:batch_ys})\n",
    "        total_cost+=cv\n",
    "    print(\"에폭:\", \"%4d\" % (epoch+1),\n",
    "         'avg cost=', \"{:.3f}\".format(total_cost/total_batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에폭:    1 avg cost= 0.529\n",
      "에폭:    2 avg cost= 0.246\n",
      "에폭:    3 avg cost= 0.186\n",
      "에폭:    4 avg cost= 0.157\n",
      "에폭:    5 avg cost= 0.137\n",
      "에폭:    6 avg cost= 0.125\n",
      "에폭:    7 avg cost= 0.120\n",
      "에폭:    8 avg cost= 0.117\n",
      "에폭:    9 avg cost= 0.117\n",
      "에폭:   10 avg cost= 0.100\n",
      "에폭:   11 avg cost= 0.098\n",
      "에폭:   12 avg cost= 0.097\n",
      "에폭:   13 avg cost= 0.095\n",
      "에폭:   14 avg cost= 0.089\n",
      "에폭:   15 avg cost= 0.086\n",
      "에폭:   16 avg cost= 0.082\n",
      "에폭:   17 avg cost= 0.078\n",
      "에폭:   18 avg cost= 0.078\n",
      "에폭:   19 avg cost= 0.076\n",
      "에폭:   20 avg cost= 0.075\n",
      "에폭:   21 avg cost= 0.071\n",
      "에폭:   22 avg cost= 0.079\n",
      "에폭:   23 avg cost= 0.076\n",
      "에폭:   24 avg cost= 0.066\n",
      "에폭:   25 avg cost= 0.071\n",
      "에폭:   26 avg cost= 0.060\n",
      "에폭:   27 avg cost= 0.065\n",
      "에폭:   28 avg cost= 0.068\n",
      "에폭:   29 avg cost= 0.066\n",
      "에폭:   30 avg cost= 0.069\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch=int(mnist.train.num_examples/batch_size)\n",
    "for epoch in range(total_epoch):\n",
    "    total_cost=0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys=mnist.train.next_batch(batch_size)\n",
    "        batch_xs=batch_xs.reshape((batch_size, n_step, n_input))\n",
    "        # [batch_size, nstep, ninput]        \n",
    "        _, cv=sess.run([optimizer, cost], feed_dict={x:batch_xs, y:batch_ys})\n",
    "        total_cost+=cv\n",
    "    print(\"에폭:\", \"%4d\" % (epoch+1),\n",
    "         'avg cost=', \"{:.3f}\".format(total_cost/total_batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.976\n"
     ]
    }
   ],
   "source": [
    "is_correct=tf.equal(tf.argmax(model,1), tf.argmax(y,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "test_batch_size=len(mnist.test.images)\n",
    "\n",
    "test_xs=mnist.test.images.reshape(test_batch_size, n_step, n_input)\n",
    "test_ys=mnist.test.labels\n",
    "\n",
    "print(\"정확도:\", sess.run(accuracy, feed_dict={x:test_xs, y:test_ys}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18,\n",
       " 't': 19,\n",
       " 'u': 20,\n",
       " 'v': 21,\n",
       " 'w': 22,\n",
       " 'x': 23,\n",
       " 'y': 24,\n",
       " 'z': 25}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_arr = ['a', 'b', 'c', 'd', 'e', 'f', 'g',\n",
    "            'h', 'i', 'j', 'k', 'l', 'm', 'n',\n",
    "            'o', 'p', 'q', 'r', 's', 't', 'u',\n",
    "            'v', 'w', 'x', 'y', 'z']\n",
    "num_dic={n:i for i,n in enumerate(char_arr)}\n",
    "num_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in enumerate(char_arr):\n",
    "    print(\"index : {}, value: {}\".format(i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'test','free','make','show','take','four'}\n",
    "# 입력: tes(3글자)\n",
    "# 출력: est(3글자)\n",
    "\n",
    "1. 단어를 글자단위(voc)로 나눔. 원핫인코딩\n",
    "2. 트레이닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
